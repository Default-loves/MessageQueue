





### Flink

Flink架构：

![image](F:\MyGitHub\my\MessageQueue\pic\Flink架构.png)

每个TaskManager都是一个Java进程，负责执行任务

JobManager负责管理所有的计算节点和计算任务



流计算的适用场景：对实时产生的数据进行实时的数据统计分析

### 例子

接收 NGINX 的 access.log，每 5 秒钟按照 IP 地址统计 Web 请求的次数

```scala

object SocketWindowIpCount {

  def main(args: Array[String]) : Unit = {

    // 获取运行时环境
    val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment
    // 按照EventTime来统计
    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    // 设置并行度
    env.setParallelism(4)

    // 定义输入：从Socket端口中获取数据输入
    val hostname: String = "localhost"
    val port: Int = 9999
    // Task 1
    val input: DataStream[String] = env.socketTextStream(hostname, port, '\n')

    // 数据转换：将非结构化的以空格分隔的文本转成结构化数据IpAndCount
    // Task 2
    input
      .map { line => line.split("\\s") }
      .map { wordArray => IpAndCount(new SimpleDateFormat("HH:mm:ss").parse(wordArray(0)), wordArray(1), 1) }

    // 计算：每5秒钟按照ip对count求和

      .assignAscendingTimestamps(_.date.getTime) // 告诉Flink时间从哪个字段中获取


      .keyBy("ip") // 按照ip地址统计
      // Task 3
      .window(TumblingEventTimeWindows.of(Time.seconds(5))) // 每5秒钟统计一次
      .sum("count") // 对count字段求和

    // 输出：转换格式，打印到控制台上

      .map { aggData => new SimpleDateFormat("HH:mm:ss").format(aggData.date) + " " + aggData.ip + " " + aggData.count }
      .print()

    env.execute("Socket Window IpCount")
  }

  /** 中间数据结构 */

  case class IpAndCount(date: Date, ip: String, count: Long)
}
```





流计算中如果出现了节点故障导致任务失败，由于数据时没有进行持久化的，所以会导致数据的丢失。Flink的做法是直接重启整个计算任务，并且从数据源头回溯一些数据，但是对于接受计算结果的下游系统来说，可能会存在重复数据。为此，我们使用Kafka的Exactly Once来解决

Flink集群内部保证Exactly Once

使用Checkpoint机制来定期保存节点的状态和数据源计算的位置，数据流进入Flink后会被插入一条特殊的数据Barrier，数据流就被多个Barrier分为多段，当Barrier流过每个计算节点的时候，会触发计算节点保存Checkpoint，当Barrier流出Flink集群的时候，说明Barrier所在的数据Checkpoint已经记录完毕。

当有节点宕机的时候，重启任务到最近的Checkpoint重新计算，此时节点的状态和数据源的计算位置是正确的，不会重复计算消息

端到端的Exactly Once，这儿的端到端指的是Kafka的的主题A，经过Flink统计计算后，发送到Kafka的主题B

利用Kafka的事务和生产幂等可以实现端到端的Exactly Once。

Kafka的事务能够保证一个事务内的所有消息要么都成功投递，要么失败

生产幂等是消息发送给Broker不会重复

当Flink创建Checkpoint后，同时开启一个Kafka的事务，完成Checkpoint的时候提交事务。当由于节点宕机Flink回到最近的Checkpoint，这个状态对应了Kafka上一个提交的事务，而没有提交的事务就会被丢弃，从而能够实现端到端的Exactly Once